{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lighter Architectures for Audio Scene Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we first train **ResNet34** to classify the audio scenes, and then train a lighter model developed for the DCase21 challenge called **sp4sc**, which implement separable convolutions and merges batch normalization with convolutional layer at test time.\n",
    "\n",
    "**Note:** In this notebook, we do not compare the results, training times, and performances, this will be done within the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.models as models\n",
    "import librosa\n",
    "import time\n",
    "\n",
    "#utils\n",
    "from utils import *\n",
    "\n",
    "#code from original repository\n",
    "from sp4asc.models.cnns import LogMelSpectrogram, Cnn6_60k, Cnn6\n",
    "from sp4asc.models import get_net\n",
    "from sp4asc.training import TrainingManager\n",
    "from sp4asc.testing import TestManager\n",
    "\n",
    "\n",
    "\n",
    "## General Config of Notebook\n",
    "\n",
    "config = {\n",
    "    \"batchsize\": 32,\n",
    "    \"num_workers\": 4,\n",
    "    \"reload\": False,\n",
    "    \"net\": \"Cnn6_60k\",\n",
    "    \"dropout\": 0.2,\n",
    "    \"specAugment\": [128, 2, 16, 2],\n",
    "    \"lr\": 1e-3,\n",
    "    \"eta_min\": 1e-5,\n",
    "    \"max_epoch\": 100,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"mixup_alpha\": 0.2,\n",
    "    \"out_dir\": \"./trained_models/log\",\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using \",device,\" device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset with all the data\n",
    "\n",
    "dataset = DCaseDataset(\"data\")\n",
    "length = len(dataset)\n",
    "\n",
    "val_split = int(0.9*length)\n",
    "data_train_test, data_val = random_split(dataset,[val_split, length - val_split])\n",
    "length_train_test = len(data_train_test)\n",
    "train_n = int(0.7*length_train_test)\n",
    "eval_n = length_train_test - train_n\n",
    "\n",
    "# split it into train and test datasets\n",
    "data_train, data_eval = random_split(data_train_test,[train_n, eval_n])\n",
    "\n",
    "\n",
    "# ---\n",
    "loader_train = DataLoader(\n",
    "    data_train,\n",
    "    batch_size=config[\"batchsize\"],\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    drop_last=True,\n",
    ")\n",
    "loader_test = DataLoader(\n",
    "    data_eval,\n",
    "    batch_size=config[\"batchsize\"],\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    drop_last=False,\n",
    ")\n",
    "loader_val = DataLoader(\n",
    "    data_val,\n",
    "    batch_size=config[\"batchsize\"],\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"train len:\", len(data_train))\n",
    "print(\"eval len:\", len(data_eval))\n",
    "print(\"val len:\", len(data_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Big Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "\n",
    "# Replacing the layers to resize the output to 10 \n",
    "model.fc = nn.Linear(512,10)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathModel = \"trained_models/resnet/resnet34.pth\" # find the pretrained resnet, and retrain only two layers\n",
    "# model.load_state_dict(torch.load(pathModel))\n",
    "\n",
    "model.eval()\n",
    "print(\"number of parameters in the model: \",count_parameters(model))\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = LogMelSpectrogram()\n",
    "#spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
    "#spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
    "\n",
    "# ---\n",
    "optim = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": model.parameters()},\n",
    "    ],\n",
    "    lr=config[\"lr\"],\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim,\n",
    "    config[\"max_epoch\"],\n",
    "    eta_min=config[\"eta_min\"],\n",
    ")\n",
    "\n",
    "# --- Training\n",
    "mng = TrainingManager(\n",
    "    model,\n",
    "    spectrogram,\n",
    "    loader_train,\n",
    "    loader_test,\n",
    "    optim,\n",
    "    scheduler,\n",
    "    config,\n",
    "    config[\"out_dir\"],\n",
    ")\n",
    "\n",
    "mng.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real = []\n",
    "resume=[]\n",
    "\n",
    "for i, data in enumerate(loader_test):\n",
    "    x,y, path=data\n",
    "    x.to(device)\n",
    "    #print(path)\n",
    "    x=spectrogram(x)\n",
    "    y_pred=model(x)\n",
    "    #print(y_pred)\n",
    "    #print(np.shape(y_pred))\n",
    "    y_pred=torch.argmax(y_pred, dim=1)\n",
    "    resume.append(y_pred)\n",
    "    real.append(y)\n",
    "    print(f'y pred is {y_pred}')\n",
    "    print(f'y is {y}')\n",
    "    \n",
    "    plot_confusion_matrix(real,resume, [0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the CNN6 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = [Cnn6]\n",
    "get_net = {str(n.__name__): n for n in nets}\n",
    "\n",
    "config_cnn6 = {\n",
    "    \"batchsize\": 32,\n",
    "    \"num_workers\": 4,\n",
    "    \"reload\": False,\n",
    "    \"net\": \"Cnn6\",\n",
    "    \"dropout\": 0.2,\n",
    "    \"specAugment\": [128, 2, 16, 2],\n",
    "    \"lr\": 1e-3,\n",
    "    \"eta_min\": 1e-5,\n",
    "    \"max_epoch\": 100,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"mixup_alpha\": 0.2,\n",
    "    \"out_dir\": \"./trained_models/log\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log dir\n",
    "path2log = config_cnn6[\"out_dir\"]\n",
    "os.makedirs(path2log, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Get network\n",
    "spectrogram = LogMelSpectrogram()\n",
    "net = get_net[config_cnn6[\"net\"]](\n",
    "    config_cnn6[\"dropout\"],\n",
    "    config_cnn6[\"specAugment\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log dir\n",
    "path2log = config_cnn6[\"out_dir\"]\n",
    "os.makedirs(path2log, exist_ok=True)\n",
    "\n",
    "# --- Get network\n",
    "spectrogram = LogMelSpectrogram()\n",
    "net = get_net[config_cnn6[\"net\"]](\n",
    "    config_cnn6[\"dropout\"],\n",
    "    config_cnn6[\"specAugment\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nNet at training time\")\n",
    "print(net)\n",
    "print(\"Nb. of parameters at training time: \", net.get_nb_parameters() / 1e3, \"k\")\n",
    "\n",
    "# ---\n",
    "optim = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": net.parameters()},\n",
    "    ],\n",
    "    lr=config[\"lr\"],\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim,\n",
    "    config[\"max_epoch\"],\n",
    "    eta_min=config[\"eta_min\"],\n",
    ")\n",
    "\n",
    "# --- Training\n",
    "mng = TrainingManager(\n",
    "    net,\n",
    "    spectrogram,\n",
    "    loader_train,\n",
    "    loader_test,\n",
    "    optim,\n",
    "    scheduler,\n",
    "    config,\n",
    "    path2log,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mng.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load and train the sp4sc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = [Cnn6_60k]\n",
    "get_net = {str(n.__name__): n for n in nets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log dir\n",
    "path2log = config[\"out_dir\"]\n",
    "os.makedirs(path2log, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Get network\n",
    "spectrogram = LogMelSpectrogram()\n",
    "net = get_net[config[\"net\"]](\n",
    "    config[\"dropout\"],\n",
    "    config[\"specAugment\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training by distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nNet at training time\")\n",
    "print(net)\n",
    "print(\"Nb. of parameters at training time: \", net.get_nb_parameters() / 1e3, \"k\")\n",
    "\n",
    "# ---\n",
    "optim = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": net.parameters()},\n",
    "    ],\n",
    "    lr=config[\"lr\"],\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim,\n",
    "    config[\"max_epoch\"],\n",
    "    eta_min=config[\"eta_min\"],\n",
    ")\n",
    "\n",
    "# --- Training\n",
    "mng = TrainingManager(\n",
    "    net,\n",
    "    spectrogram,\n",
    "    loader_train,\n",
    "    loader_test,\n",
    "    optim,\n",
    "    scheduler,\n",
    "    config,\n",
    "    path2log,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mng.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving current state of our Training Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_save = {\n",
    "    \"epoch\": mng.current_epoch,\n",
    "    \"net\": mng.net.state_dict(),\n",
    "    \"optim\": mng.optim.state_dict(),\n",
    "    \"scheduler\": mng.scheduler.state_dict(),\n",
    "    \"config\": mng.config,\n",
    "}\n",
    "\n",
    "mng.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Test Manager without Batch Normalization Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mngTest = TestManager(\n",
    "    net,\n",
    "    spectrogram,\n",
    "    loader_val,\n",
    "    loader_test,\n",
    "    path2model=\"./trained_models/log/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "mngTest.test(merge_bn=False)\n",
    "print(f'Took {time.time() - start_time} sec to run')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Test Manager without Batch Normalization Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mngTest = TestManager(\n",
    "    net,\n",
    "    spectrogram,\n",
    "    loader_val,\n",
    "    loader_test,\n",
    "    path2model=\"./trained_models/log/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Testing\n",
    "start_time = time.time()\n",
    "mngTest.test(merge_bn=True)\n",
    "print(f'Took {time.time() - start_time} sec to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DCase",
   "language": "python",
   "name": "dcase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "27643fe363c4943d5626e812d500244a90edc5f62a8d94ffccec12afdfd0986b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
